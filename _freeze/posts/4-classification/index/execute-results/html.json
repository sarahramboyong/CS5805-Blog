{
  "hash": "2be6ed5e9e9c422d40927bf7c1093690",
  "result": {
    "markdown": "---\ntitle: \"Classification\"\nauthor: \"Sarah Ramboyong\"\ndate: \"2023-12-6\"\nimage: \"classification_image.jpg\"\n---\n\n# Introduction \n\nClassification is a supervised machine learning technique that attempts to predict the correct label for the given data points. There are three phases in supervised learning. \n\n1. The model is trained on a subset of the data and is given both the input data and its labels.\n2. It is then evaluated on the testing subset.\n3. Finally, it predicts labels on new unseen data. This is called validation. \n\n\nMachine learning classification algorithms are split into two types: eager learners and lazy learners. Eager learners build the model from the training dataset before making any predictions on future datasets. Lazy learners memorize the training data and refer to those past inputs and outputs to make predictions on future points. For these reasons, eager learners are typically perform faster than lazy learners.\n\nIn this blog post we will be implementing two different classification models, decision trees and K-Nearest Neighbor. Decision trees are eager learners while K-Nearest Neighbor is a lazy learning. We will be using the SMS Spam Collection dataset from the UCI Machine Learning Repository. This dataset contains 5,574 SMS messages in English, labeled ham (legitimate) or spam. This dataset is publically avaliable on [The UCI Machine Learning Repository Website](https://archive.ics.uci.edu/dataset/228/sms+spam+collection).\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# Load the SMS Spam Collection dataset\nimport pandas as pd\n\n# Load the SMS Spam Collection dataset\ndf = pd.read_csv(\"C:/Users/sarah/git/CS5805-Blog/posts/4-classification/SMSSpamCollection\", sep=\"\\t\", names=[\"label\", \"message\"])\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nBefore we can perform classification algorithms we will first need todo some preprocessing steps. \n1. Convert all text to lowercase to ensure that words are treated the same, regardless of case\n2. Remove all punctuation to reduce noise\n3. Remove all stop words. Stopwords are common words like 'is', 'the', 'and', etc. that usually don't carry much information.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport warnings\nwarnings.filterwarnings('ignore')\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nimport re\n\n# Download the stopwords from NLTK\nnltk.download('stopwords')\n\nstemmer = PorterStemmer()\n\n# Function to preprocess text\ndef preprocess(text):\n    # Convert to lower case\n    text = text.lower()\n    # Remove punctuation\n    text = re.sub('[^a-z]', ' ', text)\n    # Remove stopwords and stem the words\n    text = ' '.join(word for word in text.split() if word not in set(stopwords.words('english')))\n    return text\n\n# Apply the preprocessing to each message\ndf['message'] = df['message'].apply(preprocess)\ndf['message'].head()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\sarah\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n0    go jurong point crazy available bugis n great ...\n1                              ok lar joking wif u oni\n2    free entry wkly comp win fa cup final tkts st ...\n3                  u dun say early hor u c already say\n4               nah think goes usf lives around though\nName: message, dtype: object\n```\n:::\n:::\n\n\nNow we can begin performing classification.\n\n# Decision Trees\n\nA decision tree is a supervised algorithm that has a heirarchial, tree structure. It can be visualized as a flowchart-like diagram and is made up of decision nodes and leaves. The decision nodes are where the features are evaluated and the leaves represent the final outcome.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.metrics import classification_report\n\n# Convert the text messages to a matrix of token counts\ncv = CountVectorizer()\nX = cv.fit_transform(df['message']).toarray()\ny = df['label']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train a Decision Tree model\nclf = DecisionTreeClassifier()\nclf.fit(X_train, y_train)\n\n# Make predictions on the testing data\ny_pred = clf.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy}')\n\n# Calculate confusion matrix\nconf_mat = confusion_matrix(y_test, y_pred)\nprint(f'Confusion Matrix: \\n{conf_mat}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy: 0.9713004484304932\nConfusion Matrix: \n[[953  13]\n [ 19 130]]\n```\n:::\n:::\n\n\nWe see that the accuracy of our decision tree on the Spam Collection dataset was 97.58%. Our confusion matrix shows that 956 messages were correctly labeled ham (legitimate) and 132 were correctly labeled spam. We also see that 10 messages were legitimate but labeled spam, and 17 were spam but labeled legitimate. This dataset is 86.6% legitimate messages and 13.4% spam messages, so it is expected that the model will over classify messages as legitimate.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# Print a classification report\nprint(classification_report(y_test, y_pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              precision    recall  f1-score   support\n\n         ham       0.98      0.99      0.98       966\n        spam       0.91      0.87      0.89       149\n\n    accuracy                           0.97      1115\n   macro avg       0.94      0.93      0.94      1115\nweighted avg       0.97      0.97      0.97      1115\n\n```\n:::\n:::\n\n\nThe classification report gives additional metrics on our model. We can see that the precision, the proportion of true positives predictions to the total number of postives that the model predicts, was high for both ham and spam. The recall is the proportion of true positives predictions to all true data points. Recall was very high for ham, and relatively high for spam. The F1 score is the trade-off between these two measures and again, it was very high for ham and relativley high for spam.\n\nWe can also visualize the decision model that we trained using sklean's plot_tree function.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nfrom sklearn.tree import plot_tree\nimport matplotlib.pyplot as plt\n\n# Plot the decision tree\nplt.figure(figsize=(20,10))\nplot_tree(clf, filled=True, rounded=True, class_names=['Ham', 'Spam'], feature_names=cv.get_feature_names_out())\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-1.png){width=1507 height=758}\n:::\n:::\n\n\nWe see that the decision tree that we generated is very large, which makes sense seeing that the dataset contains just under 5,000 messages.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nprint(clf.tree_.node_count)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n261\n```\n:::\n:::\n\n\nUsing the built-in function, we see that there are 261 nodes in this decision tree. The number of branches is always # nodes - 1, so we also know that there are 260 branches in this tree.\n\n# K-Nearest Neighbor\n\nK-Nearest Neighbor (KNN) is another type of supervised learning algorithm. \nIt uses the distance between points to identify the nearest K neighbors and assign a prediction label. \n\nFirst we have to select the K number of neighbors to calculate the distance to. Generally it is best practice to select an odd number for k to avoid ties in classification. For large datasets and datasets with more noise, it is usually best to select a large value for k.\n\nA common practice of finding the optimal K is by taking the square root of the total number of samples. In our case, $\\sqrt(4827)=69.47$. We will implement KNN using K=69.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report\n\n# Convert the text messages to a matrix of token counts\ncv = CountVectorizer()\nX = cv.fit_transform(df['message']).toarray()\ny = df['label']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train a KNN model\nknn = KNeighborsClassifier(n_neighbors=69)\nknn.fit(X_train, y_train)\n\n# Make predictions on the testing data\ny_pred = knn.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy}')\n\n# Calculate confusion matrix\nconf_mat = confusion_matrix(y_test, y_pred)\nprint(f'Confusion Matrix: \\n{conf_mat}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy: 0.8663677130044843\nConfusion Matrix: \n[[966   0]\n [149   0]]\n```\n:::\n:::\n\n\nWe see that the accuracy on this dataset using KNN is 86.64%. The confusion matrix shows that 149 spam messages were incorrectly labeled as ham, and no ham messages were incorrectly labeled as spam. \n\nWe will attempt to find a more optimal K by rerunning the algorithm multiple times and selecting the K that gives the highest accuracy.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nfrom sklearn.metrics import accuracy_score\n\n# List of possible K values\nk_values = list(range(3, 80))\n\n# List to store accuracy for each K\naccuracy_list = []\n\n# Loop over possible K values\nfor k in k_values:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    y_pred = knn.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    accuracy_list.append(accuracy)\n\n# Find K that gives highest accuracy\noptimal_k = k_values[accuracy_list.index(max(accuracy_list))]\n\nprint(f'Optimal K is {optimal_k} with accuracy of {max(accuracy_list)}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOptimal K is 3 with accuracy of 0.9345291479820628\n```\n:::\n:::\n\n\nFrom this we find that the best K is actually 3, with an accuracy of 93.45%. We will run the model and metrics one last time with this optimal K.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n# Train a KNN model\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\n\n# Make predictions on the testing data\ny_pred = knn.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy}')\n\n# Calculate confusion matrix\nconf_mat = confusion_matrix(y_test, y_pred)\nprint(f'Confusion Matrix: \\n{conf_mat}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy: 0.9345291479820628\nConfusion Matrix: \n[[966   0]\n [ 73  76]]\n```\n:::\n:::\n\n\nThe confusion matric for our new optimal K=3 shows that, again, no ham messages were incorrectly labeled as spam and 73 spam messages were incorrectly labeled as ham.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\n# Print a classification report\nprint(classification_report(y_test, y_pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              precision    recall  f1-score   support\n\n         ham       0.93      1.00      0.96       966\n        spam       1.00      0.51      0.68       149\n\n    accuracy                           0.93      1115\n   macro avg       0.96      0.76      0.82      1115\nweighted avg       0.94      0.93      0.93      1115\n\n```\n:::\n:::\n\n\n# Conclusion\n\nOverall our decision tree achieved a higher accuracy of 97.58% while our KNN model achieved 93.45% at best. The KNN model showcased the downsides of lazy learner models, as well as the potential problems with having an unbalanced training set. \n\n\n## References:\n* https://www.datacamp.com/blog/classification-machine-learning\n* https://www.datacamp.com/tutorial/decision-tree-classification-python\n* https://archive.ics.uci.edu/dataset/228/sms+spam+collection\n* https://www.labelf.ai/blog/what-is-accuracy-precision-recall-and-f1-score\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}
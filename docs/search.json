[
  {
    "objectID": "posts/5-anomaly/index.html",
    "href": "posts/5-anomaly/index.html",
    "title": "Anomaly & Outlier Detection",
    "section": "",
    "text": "This is a post with executable code will be about anomaly detection"
  },
  {
    "objectID": "posts/3-linear/index.html",
    "href": "posts/3-linear/index.html",
    "title": "Linear & Non-linear Regression",
    "section": "",
    "text": "Regression is a statitical method that allows on to predict the output of one variables based on the input of another. It is a way of quantifying the relationship between a dependent variable (Y) and one or more independent variables (X).\nThere are two types of regression: linear and non-linear. Linear regression uses one independent variable to predict the outcome of the dependent variable. It follows the equation: \\(y=mx+b\\) where m is the slope, or the rate of change, and b is the intercept.\nNon-linear regression is used when there is a relationship between the dependent variable and more than one indepent variables. It follows the equation:\nNon-linear regression, or multi-linear regression, accounts for the majority of real-life data which are complex and often influences b\n\n\n\nhttps://www.investopedia.com/terms/r/regression.asp#:~:text=%25%2025%25%200%25-,What%20Is%20a%20Regression%3F,(known%20as%20independent%20variables)."
  },
  {
    "objectID": "posts/3-linear/index.html#referenes",
    "href": "posts/3-linear/index.html#referenes",
    "title": "Linear & Non-linear Regression",
    "section": "",
    "text": "https://www.investopedia.com/terms/r/regression.asp#:~:text=%25%2025%25%200%25-,What%20Is%20a%20Regression%3F,(known%20as%20independent%20variables)."
  },
  {
    "objectID": "posts/1-probability/index.html",
    "href": "posts/1-probability/index.html",
    "title": "Probability Theory & Random Variables",
    "section": "",
    "text": "This blog will be all about probability theory & random variables…. maybe histograms?\nWe could write about predicting probabiliyt an dhow it has to add to 1?"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sarah Ramboyong",
    "section": "",
    "text": "Hello and welcome to my blog!\nSarah is a Masters of Engineering student at Virginia Tech studying Computer Science, with a concentration in Data Analytics and AI. When not studying, Sarah enjoys hiking, traveling, and spending time with her friends and family.\n\n\nVirginia Tech | Blacksburg, VA MEng in Computer Science | Aug 2022 - May 2024\nVirginia Tech | Blacksburg, VA B.s in Computational Modeling & Data Analytics | Aug 2020 - May 2023\n\n\n\nThis blog was created as an assignment for Virginia Tech’s CS 5805: Machine Learning. Sarah would like to express her gratitude to the teaching staff of this course, and especially to Dr. Martin Skarzynski for a great semester."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Sarah Ramboyong",
    "section": "",
    "text": "Virginia Tech | Blacksburg, VA MEng in Computer Science | Aug 2022 - May 2024\nVirginia Tech | Blacksburg, VA B.s in Computational Modeling & Data Analytics | Aug 2020 - May 2023"
  },
  {
    "objectID": "about.html#acknowledgement",
    "href": "about.html#acknowledgement",
    "title": "Sarah Ramboyong",
    "section": "",
    "text": "This blog was created as an assignment for Virginia Tech’s CS 5805: Machine Learning. Sarah would like to express her gratitude to the teaching staff of this course, and especially to Dr. Martin Skarzynski for a great semester."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CS5805: Machine Learning Blog",
    "section": "",
    "text": "Probability Theory & Random Variables\n\n\n\n\n\n\n\n\n\n\n\n\nDec 6, 2023\n\n\nSarah Ramboyong\n\n\n\n\n\n\n  \n\n\n\n\nClustering\n\n\n\n\n\n\n\n\n\n\n\n\nDec 6, 2023\n\n\nSarah Ramboyong\n\n\n\n\n\n\n  \n\n\n\n\nLinear & Non-linear Regression\n\n\n\n\n\n\n\n\n\n\n\n\nDec 6, 2023\n\n\nSarah Ramboyong\n\n\n\n\n\n\n  \n\n\n\n\nClassification\n\n\n\n\n\n\n\n\n\n\n\n\nDec 6, 2023\n\n\nSarah Ramboyong\n\n\n\n\n\n\n  \n\n\n\n\nAnomaly & Outlier Detection\n\n\n\n\n\n\n\n\n\n\n\n\nDec 6, 2023\n\n\nSarah Ramboyong\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2-clustering/index.html",
    "href": "posts/2-clustering/index.html",
    "title": "Clustering",
    "section": "",
    "text": "Clustering a is an unsupervised machine learning technique that groups data points into a specified number of groups. This grouping is based on shared characteristics, so points in the same cluster are similar to one another and dissimilar to points in other clusters.\nThere are many appliciations of clustering, for example:\n\nBiology - identifying shared characteristics across different species\nMarketing - understanding consumer behavior\nCybersecurity - visualizing network traffic and patterns for improved anomaly detection\nImage segmentation - object recognition and isolation\n\nIn this blog post we will be implementing the K-Means clustering algorithm. We will be using the palmer penguin dataset which includes size measurements, clutch observations, and blood isotope ratios for 344 adult penguins observed on islands surrounding Palmer Station, Antarctica. This dataset is publically avaliable on GitHub.\n\n# Load the Palmer Penguins dataset\nimport pandas as pd\nfrom palmerpenguins import load_penguins\npenguins = load_penguins()\npenguins.dropna(inplace=True)  # drop nan values\nX = penguins.iloc[:, 2:6]\ny = pd.factorize(penguins[\"species\"])[0]"
  },
  {
    "objectID": "posts/2-clustering/index.html#references",
    "href": "posts/2-clustering/index.html#references",
    "title": "Clustering",
    "section": "References:",
    "text": "References:\n\nhttps://www.geeksforgeeks.org/clustering-in-machine-learning/\nhttps://www.datacamp.com/blog/clustering-in-machine-learning-5-essential-clustering-algorithms\nhttps://github.com/mcnakhaee/palmerpenguins\nhttps://www.w3schools.com/python/python_ml_k-means.asp\nhttps://builtin.com/data-science/elbow-method"
  },
  {
    "objectID": "posts/4-classification/index.html",
    "href": "posts/4-classification/index.html",
    "title": "Classification",
    "section": "",
    "text": "Classification is a supervised machine learning technique that attempts to predict the correct label for the given data points. There are three phases in supervised learning. 1. The model is trained on a subset of the data and is given both the input data and its labels. 2. It is then evaluated on the testing subset. 3. Finally, it predicts labels on new unseen data. This is called validation.\nMachine learning classification algorithms are split into two types: eager learners and lazy learners. Eager learners build the model from the training dataset before making any predictions on future datasets. Lazy learners memorize the training data and refer to those past inputs and outputs to make predictions on future points. For these reasons, eager learners are typically perform faster than lazy learners.\nIn this blog poast we will be implementing two different classification models, decision trees and K-Nearest Neighbor. Decision trees are eager learners while K-Nearest Neighbor is a lazy learning. We will be using the….. dataset."
  },
  {
    "objectID": "posts/4-classification/index.html#references",
    "href": "posts/4-classification/index.html#references",
    "title": "Classification",
    "section": "References:",
    "text": "References:\n\nhttps://www.datacamp.com/blog/classification-machine-learning"
  }
]